{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bb6bdd",
   "metadata": {},
   "source": [
    "# An introduction to `relatio` \n",
    "**Runtime $\\sim$ 5min**\n",
    "\n",
    "Original paper: [\"Text Semantics Capture Political and Economic Narratives\"](https://arxiv.org/abs/2108.01720)\n",
    "\n",
    "----------------------------\n",
    "\n",
    "This is a short demo of the package `relatio`.  It takes as input a text corpus and outputs a list of narrative statements. The pipeline is unsupervised: the user does not need to specify narratives beforehand. Narrative statements are defined as tuples of semantic roles with a (agent, verb, patient, attribute) structure. \n",
    "\n",
    "Here, we present the main wrapper functions to quickly obtain narrative statements from a corpus.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "In this tutorial, we work with tweets from candidates at the French Presidential Elections (2022).\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17886d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/germain/Desktop/relatio/.tox/dev/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/germain/Desktop/relatio/.tox/dev/lib/python3.7/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Catch warnings for an easy ride\n",
    "from relatio import FileLogger\n",
    "logger = FileLogger(level = 'WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ed6668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"trump_tweet_archive\": \n",
      "    {\n",
      "        \"description\": \"Tweets from the Trump Tweet Archives (https://www.thetrumparchive.com/)\",\n",
      "        \"language\": \"english\",\n",
      "        \"srl_model\": \"allennlp v0.9 -- srl-model-2018.05.25.tar.gz\",\n",
      "        \"links\": \n",
      "        {\n",
      "            \"raw\": \"https://www.dropbox.com/s/lxqz454n29iqktn/trump_archive.csv?dl=1\",\n",
      "            \"sentences\": \"https://www.dropbox.com/s/coh4ergyrjeolen/split_sentences.json?dl=1\",\n",
      "            \"srl_res\": \"https://www.dropbox.com/s/54lloy84ka8mycp/srl_res.json?dl=1\"\n",
      "        }\n",
      "    },\n",
      "    \"tweets_candidates_french_elections\": \n",
      "    {\n",
      "        \"description\": \"Tweets of candidates at the French presidential elections (2022)\",\n",
      "        \"language\": \"french\",\n",
      "        \"srl_model\": \"\",\n",
      "        \"links\": \n",
      "        {\n",
      "            \"raw\": \"https://www.dropbox.com/s/qqlq8xn9x645f79/tweets_candidates_french_elections.csv?dl=1\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from relatio import list_data\n",
    "list_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c8fa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc</th>\n",
       "      <th>date</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29238</th>\n",
       "      <td>29237</td>\n",
       "      <td>Hier, nous étions à #Rennes, place Hoche, pour...</td>\n",
       "      <td>2022-02-09T16:01:00.000Z</td>\n",
       "      <td>yjadot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29239</th>\n",
       "      <td>29238</td>\n",
       "      <td>Pensées à ses proches</td>\n",
       "      <td>2022-02-09T15:31:36.000Z</td>\n",
       "      <td>yjadot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29240</th>\n",
       "      <td>29239</td>\n",
       "      <td>Un an déjà que Guillaume, militant communiste ...</td>\n",
       "      <td>2022-02-09T15:31:16.000Z</td>\n",
       "      <td>yjadot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29241</th>\n",
       "      <td>29240</td>\n",
       "      <td>Le #OneOceanSummit s'ouvre aujourd'hui à #Bres...</td>\n",
       "      <td>2022-02-09T15:03:00.000Z</td>\n",
       "      <td>yjadot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29242</th>\n",
       "      <td>29241</td>\n",
       "      <td>Pour revoir l'intégralité de mon passage sur @...</td>\n",
       "      <td>2022-02-09T14:00:03.000Z</td>\n",
       "      <td>yjadot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                doc  \\\n",
       "29238  29237  Hier, nous étions à #Rennes, place Hoche, pour...   \n",
       "29239  29238                              Pensées à ses proches   \n",
       "29240  29239  Un an déjà que Guillaume, militant communiste ...   \n",
       "29241  29240  Le #OneOceanSummit s'ouvre aujourd'hui à #Bres...   \n",
       "29242  29241  Pour revoir l'intégralité de mon passage sur @...   \n",
       "\n",
       "                           date candidate  \n",
       "29238  2022-02-09T16:01:00.000Z    yjadot  \n",
       "29239  2022-02-09T15:31:36.000Z    yjadot  \n",
       "29240  2022-02-09T15:31:16.000Z    yjadot  \n",
       "29241  2022-02-09T15:03:00.000Z    yjadot  \n",
       "29242  2022-02-09T14:00:03.000Z    yjadot  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relatio import load_data\n",
    "df = load_data(dataset = \"tweets_candidates_french_elections\", content = \"raw\")\n",
    "df = df[df['candidate'] == 'yjadot']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb97e000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3432/3432 [00:03<00:00, 978.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from relatio import Preprocessor\n",
    "\n",
    "import string\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string) + ['rt']\n",
    "\n",
    "p = Preprocessor(\n",
    "    spacy_model = \"fr_core_news_sm\",\n",
    "    remove_punctuation = True,\n",
    "    remove_digits = True,\n",
    "    lowercase = True,\n",
    "    lemmatize = True,\n",
    "    remove_chars = [\"\\\"\",'-',\"^\",\".\",\"?\",\"!\",\";\",\"(\",\")\",\",\",\":\",\"\\'\",\"+\",\"&\",\"|\",\"/\",\"{\",\"}\",\n",
    "                    \"~\",\"_\",\"`\",\"[\",\"]\",\">\",\"<\",\"=\",\"*\",\"%\",\"$\",\"@\",\"#\",\"’\"],\n",
    "    stop_words = alphabet_list,\n",
    "    n_process = -1,\n",
    "    batch_size = 100\n",
    ")\n",
    "\n",
    "doc_index, sentences = p.split_into_sentences(\n",
    "    df, output_path = None, progress_bar = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7380076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SVOs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7661/7661 [00:04<00:00, 1619.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARG0': 'nous', 'B-ARGM-NEG': False, 'B-V': 'étions', 'ARG1': ''}\n",
      "{'ARG0': 'nous', 'B-ARGM-NEG': False, 'B-V': 'serons', 'ARG1': ''}\n",
      "{'ARG0': 'vous', 'B-ARGM-NEG': True, 'B-V': 'pouvez', 'ARG1': ''}\n",
      "{'ARG0': 'vous', 'B-ARGM-NEG': False, 'B-V': 'voici', 'ARG1': ''}\n",
      "{'ARG0': 'vous', 'B-ARGM-NEG': False, 'B-V': 'suivre', 'ARG1': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_index, roles = p.extract_svos(sentences, progress_bar = True)\n",
    "\n",
    "for svo in roles[0:5]: print(svo)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b336bdf",
   "metadata": {},
   "source": [
    "temp1 = pd.DataFrame(roles)\n",
    "temp1['sentence_index'] = sentence_index\n",
    "temp1['sentence_index'] = temp1['sentence_index'].astype(int)\n",
    "\n",
    "temp2 = pd.DataFrame({\"sentence\": sentences})\n",
    "temp2['sentence_index'] = temp2.index\n",
    "\n",
    "temp = temp1.merge(temp2,on='sentence_index')\n",
    "temp = temp[temp['ARG0'] == 'qui']\n",
    "temp['sentence'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478392f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10054/10054 [00:04<00:00, 2030.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role B-V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10054/10054 [00:04<00:00, 2071.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role B-ARGM-MOD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10054/10054 [00:04<00:00, 2076.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARG0': 'nous', 'B-ARGM-NEG': False}\n",
      "{'ARG0': 'nous', 'B-ARGM-NEG': False}\n",
      "{'ARG0': 'vous', 'B-V': 'pouvoir', 'B-ARGM-NEG': True}\n",
      "{'ARG0': 'vous', 'B-V': 'voici', 'B-ARGM-NEG': False}\n",
      "{'ARG0': 'vous', 'B-V': 'suivre', 'B-ARGM-NEG': False}\n"
     ]
    }
   ],
   "source": [
    "postproc_roles = p.process_roles(roles, \n",
    "                                 dict_of_pos_tags_to_keep = {\n",
    "                                     \"ARG0\": ['PRON', 'NOUN', 'PROPN'],\n",
    "                                     \"B-V\": ['VERB'],\n",
    "                                     \"ARG1\": ['NOUN', 'PROPN', 'PRON']\n",
    "                                 }, \n",
    "                                 max_length = 50,\n",
    "                                 progress_bar = True,\n",
    "                                 output_path = 'postproc_roles.json')\n",
    "\n",
    "from relatio.utils import load_roles\n",
    "postproc_roles = load_roles('postproc_roles.json')\n",
    "\n",
    "for d in postproc_roles[0:5]: print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e627dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining named entities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7661/7661 [00:09<00:00, 849.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 521)\n",
      "('écologie', 92)\n",
      "('parlement européen', 27)\n",
      "('écologi', 21)\n",
      "('primaireecologist', 19)\n",
      "('ue', 17)\n",
      "('union européen', 14)\n",
      "('humanité', 13)\n",
      "('avenir', 13)\n",
      "('tva', 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "known_entities = p.mine_entities(\n",
    "    sentences, \n",
    "    clean_entities = True, \n",
    "    progress_bar = True,\n",
    "    output_path = 'entities.pkl'\n",
    ")\n",
    "\n",
    "from relatio.utils import load_entities\n",
    "known_entities = load_entities('entities.pkl')\n",
    "\n",
    "for n in known_entities.most_common(10): print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad2f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_known_entities = [e[0] for e in list(known_entities.most_common(100)) if e[0] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d27cb731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relatio import Embeddings\n",
    "nlp_model = Embeddings(\"spaCy\", \"fr_core_news_sm\", sentences=sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ae5c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relatio import NarrativeModel\n",
    "from relatio.utils import prettify\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2415ab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding phrases...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2928/2928 [00:11<00:00, 247.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering phrases into clusters...\n",
      "Labeling the clusters by the most frequent phrases...\n"
     ]
    }
   ],
   "source": [
    "m1 = NarrativeModel(model_type = 'hdbscan',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'ARG1'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'character_matching',\n",
    "                   roles_with_unknown_entities = ['ARG0','ARG1'],\n",
    "                   embeddings_model = nlp_model,\n",
    "                   threshold = 1)    \n",
    "\n",
    "m1.fit(postproc_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d459f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting entities for role: ARG0...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5657/5657 [00:00<00:00, 15081.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching unknown entities (with clustering model)...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5657/5657 [00:15<00:00, 372.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension reduction of vectors (PCA + UMAP)...\n",
      "Assignment to clusters...\n",
      "Assigning labels to matches...\n",
      "\n",
      "Predicting entities for role: ARG1...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3556/3556 [00:00<00:00, 13900.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching unknown entities (with clustering model)...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3556/3556 [00:11<00:00, 299.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension reduction of vectors (PCA + UMAP)...\n",
      "Assignment to clusters...\n",
      "Assigning labels to matches...\n"
     ]
    }
   ],
   "source": [
    "narratives = m1.predict(postproc_roles, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24a111d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nous conditionner euro argent', 7)\n",
      "('nous donne millier milliard euro', 7)\n",
      "('nous gagner alternative qui chance', 4)\n",
      "('nous gagner élection', 4)\n",
      "('nous reprendre meeting', 3)\n",
      "('nous créer emploi', 3)\n",
      "('énergie créer emploi', 3)\n",
      "('nous donner moyen', 2)\n",
      "('nous propose primaire', 2)\n",
      "('nous allouer euro argent', 2)\n"
     ]
    }
   ],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    if n.get('ARG0') is not None:\n",
    "        if n.get('B-V') is not None:\n",
    "            if n.get('ARG1') is not None:\n",
    "                pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(10): print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "092774aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding phrases...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2928/2928 [00:11<00:00, 250.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering phrases into clusters...\n",
      "Labeling the clusters by the most frequent phrases...\n"
     ]
    }
   ],
   "source": [
    "m2 = NarrativeModel(model_type = 'kmeans',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'ARG1'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'character_matching',\n",
    "                   roles_with_unknown_entities = ['ARG0','ARG1'],\n",
    "                   embeddings_model = nlp_model,\n",
    "                   threshold = 0.3)    \n",
    "\n",
    "m2.fit(postproc_roles, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb38e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting entities for role: ARG0...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5657/5657 [00:00<00:00, 15104.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching unknown entities (with clustering model)...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5657/5657 [00:15<00:00, 361.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension reduction of vectors (PCA + UMAP)...\n",
      "Assignment to clusters...\n",
      "Assigning labels to matches...\n",
      "\n",
      "Predicting entities for role: ARG1...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3556/3556 [00:00<00:00, 13545.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching unknown entities (with clustering model)...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3556/3556 [00:11<00:00, 301.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension reduction of vectors (PCA + UMAP)...\n",
      "Assignment to clusters...\n",
      "Assigning labels to matches...\n"
     ]
    }
   ],
   "source": [
    "narratives = m2.predict(postproc_roles, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87819247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nous conditionner euro argent', 7)\n",
      "('nous donne millier milliard euro', 7)\n",
      "('nous gagner élection', 4)\n",
      "('nous reprendre andré etienne', 3)\n",
      "('nous gagner présidentielle', 3)\n",
      "('nous créer emploi', 3)\n",
      "('nous redonner sens', 3)\n",
      "('énergie créer emploi', 3)\n",
      "('nous investir milliard euro', 2)\n",
      "('nous mettre sens', 2)\n"
     ]
    }
   ],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    if n.get('ARG0') is not None:\n",
    "        if n.get('B-V') is not None:\n",
    "            if n.get('ARG1') is not None:\n",
    "                pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(10): print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7139e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relatio import build_graph, draw_graph\n",
    "\n",
    "G = build_graph(\n",
    "    narratives, \n",
    "    top_n = 100, \n",
    "    prune_network = True\n",
    ")\n",
    "\n",
    "draw_graph(\n",
    "    G,\n",
    "    notebook = False,\n",
    "    show_buttons = False,\n",
    "    width=\"1600px\",\n",
    "    height=\"1000px\",\n",
    "    output_filename = 'example.html'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
